\documentclass{article}
\usepackage[backend=bibtex,style=chicago-authordate]{biblatex}
\addbibresource{references.bib}

\begin{document}

\begin{abstract}
In the past century, the well-documented consolidation of the academic 
publishing industry created economic conditions that incentivize universities 
to publish their own academic journals. While these journals are necessary and good, 
they are not as well-funded or well-staffed as corporate players. These preconditions 
necessitate university libraries and presses to use all resources at their 
disposal to make their publishing operations run at peak efficiency. A 
large opportunity cost incurred by the university-owned publisher is 
machine-actionable metadata creation, leading to a cropping of for- and 
non-profit players in the industry to provide these services. We present 
three insights [there is a better word than insights here] - 
that reference metadata curation using LLMs is possible, that we can run 
these LLMs on local hardware, and we end with some tutorials for replication 
at other university-owned presses.  
\end{abstract}

\subsection{Background and Motivation}\label{background-and-motivation}

University-owned journal-publishing operations operate under far tighter
economic constraints --- direct and opportunity --- and therefore must
solve the same problems of corporate academic publishers with a fraction
of the resources available. One of these problems is reference metadata,
i.e.~machine-actionable references that are then used to count citations
of articles. The act of capturing, counting, and using citations accurately 
allows for funding agencies, universities, and publishers to make data-driven 
decisions for funding allocation, allows for reviewers to validate the 
research of a manuscript, and allows for faster literature review. Here, 
we evaluate the use of local large language models to curate the metadata 
with minimal human intervention.

\subsubsection{An Example}\label{an-example}

The workflow for our university --- a small, elite university in the
Mid-west United States --- consists of receiving manuscripts from
authors in a Microsoft Word file format. We then use pandoc \cite{PandocIndex}
to transform this Word document to a markdown file format, from which we can
build PDF and Web versions from a single source. But due to author unwillingness 
to use plaintext markup formats such as LaTeX or Markdown, we must recreate the 
bibliography. Previously, this mean looking up each source, adding them to a Zotero\cite{ZoteroYourPersonal}
library, and then exporting the biblatex file for use as metadata in the web version of the article.
This would allow for services such as Google Scholar and Web of Science to scrape the metadata and 
count citations for the cited articles. This allows for researchers conducting literature reviews to 
find articles easier and faster, and allows for easier cross-checking for dubious claims. The present system, 
can automate this labor-intensive machine-actionable metadata creation process. 
With the advent of Large Language Models (LLMs), we can create systems to parse out the plaintext citations 
in an article, pass it to a Large Language Model, and output a machine-actionable metadata citation entry.

\subsubsection{Limitations and Concerns}

Along with the rapid growth in users of Large-Language models, so have concerns over 
the ecological sustainability of LLM technology.\cite{dingSustainableLLMServing2024} \cite{chienReducingCarbonImpact2023}
Most of these concerns, however, can be alleviated with the use of "small" models such as 
those provided by Ollama. Further, there are concerns about the validity of Large-Language models,
especially concerning their propensity to hallucinate. However, in combination with validity checkers 
such as bibtexparser and human review, we are confident enough in this system to be used in 
production of our journals.

\subsection{Methodology}\label{methodology}



\begin{center}
\begin{tabular}{||c c c c||} 
 \hline
 Col1 & Col2 & Col2 & Col3 \\ [0.5ex] 
 \hline\hline
 1 & 6 & 87837 & 787 \\ 
 \hline
 2 & 7 & 78 & 5415 \\
 \hline
 3 & 545 & 778 & 7507 \\
 \hline
 4 & 545 & 18744 & 7560 \\
 \hline
 5 & 88 & 788 & 6344 \\ [1ex] 
 \hline
\end{tabular}
\end{center}


\subsubsection{Data Collection}\label{data-collection}

This is my data collection section.

\subsubsection{Analysis}\label{analysis}

\subsection{Results}\label{results}

\subsubsection{Discussion}\label{discussion}

\subsection{Bibliography}\label{bibliography}

\end{document}
